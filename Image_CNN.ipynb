{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60b0a06",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network)\n",
    "\n",
    "- 참고\n",
    "    - Image classification with deep convolutional neural networks (Khan et al., 2020)\n",
    "    - ImageNet Classification with Deep Convolutional Neural Networks (Krizhevsky et al., 2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f65f6",
   "metadata": {},
   "source": [
    "- Convolutional Neural Network(CNN)은 컴퓨터 비전 및 이미지 처리와 관련된 여러 대회에서 우수한 성능을 보인 특별한 유형의 신경망\n",
    "- CNN은 이미지 내의 특징을 추출하고 이를 이용해 이미지를 분류하거나 객체를 검출하는 등의 작업을 수행할 수 있음\n",
    "- CNN은 입력 이미지를 여러 개의 레이어로 처리하며, 각 레이어에서는 입력 이미지와 필터를 합성곱하여 특징 맵(feature map)을 생성\n",
    "- 이때 필터는 이미지에서 특정한 패턴을 찾아내기 위한 가중치 값으로, 학습 과정에서 자동으로 조정됨\n",
    "- 레이어를 여러 번 거침으로써, 점점 더 추상적인 특징을 추출할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed631d9a",
   "metadata": {},
   "source": [
    "- ImageNetClassification with Deep Convolutional Neural Networks에서는 8개의 레이어로 이루어진 CNN 아키텍처인 AlexNet을 제안함\n",
    "- 이 아키텍처는 풀링 레이어, 컨볼루션 레이어, 활성화 함수, 드롭아웃 레이어 등 다양한 컴포넌트로 구성됨\n",
    "- 또한, 큰 데이터셋과 병렬 컴퓨팅을 이용하여 CNN의 학습을 가속화하는 방법도 제안하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31121eb",
   "metadata": {},
   "source": [
    "- AlexNet은 기존의 신경망 아키텍처에 비해 몇 가지 차이점이 있음\n",
    "    1. 더 많은 학습 데이터 사용: AlexNet은 120만 개 이상의 이미지를 사용하여 학습\n",
    "    2. GPU를 사용한 병렬 처리: AlexNet은 2개의 GPU를 사용하여 효율적으로 학습할 수 있도록 설계\n",
    "    3. ReLU 활성화 함수 사용: 기존의 신경망에서는 sigmoid 함수나 tanh 함수를 사용했지만, AlexNet에서는 ReLU(Rectified Linear Unit) 함수를 사용하여 학습 속도를 높임\n",
    "    4. Local Response Normalization: 이전 레이어에서 활성화된 뉴런들이 다음 레이어에서 높은 활성화 값을 가지도록 정규화를 적용\n",
    "    5. Dropout: 학습 데이터에서 무작위로 뉴런을 제거하면서 학습하는 방법으로, 오버피팅(overfitting)을 방지하는 데 효과적\n",
    "- 논문에서는 또한 maxpooling과 conv2d도 자세히 설명하고 있음\n",
    "    - Maxpooling은 이미지의 크기를 줄이고, 불필요한 정보를 제거하는 데 사용됨\n",
    "    - Conv2d는 이미지에서 특징을 추출하는 데 사용되는 컨볼루션 필터를 적용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3956c",
   "metadata": {},
   "source": [
    "# 실습\n",
    "- 캐글(Kaggle)의 개 고양이 이미지 분류 대회의 이미지 데이터셋을 이용한 CNN 이미지 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7582d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 실행에 필요한 메시지 외 경고가 출력되지 않게 해줌\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c63ce3",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataGenerator = ImageDataGenerator(\n",
    "    rescale=1./255,                  # 고정 이미지 - 픽셀값을 0~255에서 0~1범위로 변경\n",
    "    shear_range=0.2,                 # 기울기 범위\n",
    "    zoom_range=0.2,                  # 확대 범위\n",
    "    horizontal_flip=True,           # 상하반전\n",
    "    validation_split=0.1            # 배치비율(예: 0.3, 0.2, 0.25 등등)\n",
    ")\n",
    "imageDataGenerator_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_dataset = imageDataGenerator.flow_from_directory(\n",
    "    \"./data/train/\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=100,\n",
    "    subset=\"training\",\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_dataset = imageDataGenerator.flow_from_directory(\n",
    "    \"./data/train/\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=100,\n",
    "    subset=\"validation\",\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_dataset = imageDataGenerator_test.flow_from_directory(\n",
    "    \"./data/test/\",\n",
    "    target_size=(128,128),\n",
    "    batch_size=100,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1deb28d",
   "metadata": {},
   "source": [
    "- 개 이미지 12,500개, 고양이 이미지 12,500개를 train/validation/test 용으로 분리하고, tensorflow의 ImageDataGenerator를 사용할 것이기 때문에 각 라벨(cat,dog)를 폴더별로 따로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f47ce",
   "metadata": {},
   "source": [
    "## 모델 생성 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99086a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T07:13:44.205487Z",
     "start_time": "2023-02-07T07:13:44.062194Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_25 (Conv2D)          (None, 128, 128, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 64, 64, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 64, 64, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 32, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                131104    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,665\n",
      "Trainable params: 155,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, kernel_size = 3, activation = \"relu\", padding = \"same\",\n",
    "                              input_shape = (128,128, 3)))\n",
    "model.add(keras.layers.MaxPool2D(2))\n",
    "model.add(keras.layers.Conv2D(16, kernel_size = 3, activation = \"relu\", padding = \"same\"))\n",
    "model.add(keras.layers.MaxPool2D(2))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size = 3, activation = \"relu\", padding = \"same\"))\n",
    "model.add(keras.layers.MaxPool2D(2))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size = 3, activation = \"relu\", padding = \"same\"))\n",
    "model.add(keras.layers.MaxPool2D(2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation = \"relu\"))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "71138730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T07:13:49.734209Z",
     "start_time": "2023-02-07T07:13:49.730703Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"./model/best-cnn-3model.h5\", save_best_only = True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b53b007a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T07:13:50.455091Z",
     "start_time": "2023-02-07T07:13:50.445106Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2a1f0c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T08:22:05.715369Z",
     "start_time": "2023-02-07T07:13:51.316667Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 201s 885ms/step - loss: 0.6478 - accuracy: 0.6076 - val_loss: 0.5838 - val_accuracy: 0.6764\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 186s 826ms/step - loss: 0.5646 - accuracy: 0.7076 - val_loss: 0.5241 - val_accuracy: 0.7272\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 185s 822ms/step - loss: 0.5202 - accuracy: 0.7446 - val_loss: 0.4835 - val_accuracy: 0.7792\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 185s 824ms/step - loss: 0.4873 - accuracy: 0.7692 - val_loss: 0.4540 - val_accuracy: 0.7804\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 183s 814ms/step - loss: 0.4716 - accuracy: 0.7815 - val_loss: 0.4525 - val_accuracy: 0.7968\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 186s 826ms/step - loss: 0.4450 - accuracy: 0.7982 - val_loss: 0.4028 - val_accuracy: 0.8128\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 189s 840ms/step - loss: 0.4263 - accuracy: 0.8103 - val_loss: 0.3936 - val_accuracy: 0.8232\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 184s 819ms/step - loss: 0.4113 - accuracy: 0.8191 - val_loss: 0.3656 - val_accuracy: 0.8368\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 187s 829ms/step - loss: 0.4000 - accuracy: 0.8270 - val_loss: 0.3604 - val_accuracy: 0.8396\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 185s 823ms/step - loss: 0.3812 - accuracy: 0.8368 - val_loss: 0.3512 - val_accuracy: 0.8412\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 186s 826ms/step - loss: 0.3700 - accuracy: 0.8411 - val_loss: 0.3625 - val_accuracy: 0.8340\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 186s 828ms/step - loss: 0.3519 - accuracy: 0.8508 - val_loss: 0.3225 - val_accuracy: 0.8520\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 187s 829ms/step - loss: 0.3441 - accuracy: 0.8566 - val_loss: 0.3323 - val_accuracy: 0.8588\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 186s 825ms/step - loss: 0.3334 - accuracy: 0.8581 - val_loss: 0.3042 - val_accuracy: 0.8652\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 184s 817ms/step - loss: 0.3233 - accuracy: 0.8662 - val_loss: 0.2984 - val_accuracy: 0.8716\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 183s 814ms/step - loss: 0.3112 - accuracy: 0.8694 - val_loss: 0.2926 - val_accuracy: 0.8756\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 184s 817ms/step - loss: 0.2991 - accuracy: 0.8784 - val_loss: 0.2995 - val_accuracy: 0.8764\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 184s 819ms/step - loss: 0.2991 - accuracy: 0.8780 - val_loss: 0.2730 - val_accuracy: 0.8840\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 184s 819ms/step - loss: 0.2828 - accuracy: 0.8840 - val_loss: 0.2719 - val_accuracy: 0.8828\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 184s 818ms/step - loss: 0.2885 - accuracy: 0.8816 - val_loss: 0.2973 - val_accuracy: 0.8708\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 184s 818ms/step - loss: 0.2663 - accuracy: 0.8924 - val_loss: 0.2838 - val_accuracy: 0.8828\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 189s 840ms/step - loss: 0.2655 - accuracy: 0.8919 - val_loss: 0.2763 - val_accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs = 100, validation_data = val_dataset,\n",
    "                    callbacks = [checkpoint_cb, early_stopping_cb])\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0d35891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T08:22:42.585136Z",
     "start_time": "2023-02-07T08:22:05.718405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 37s 291ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
